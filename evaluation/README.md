# Модульная платформа для развертывания RAG

Платформа для тестирования и оценки конвейеров поиска с дополненной генерацией (RAG) с интегрированной системой оценки RAGAS.

## Быстрый старт

### Требования
- Python 3.8+
- Poetry для управления зависимостями
- OpenAI API ключ

### Установка

1. Клонирование репозитория:
```bash
git clone <repository-url>
cd rag
```

2. Установка зависимостей:
```bash
poetry install
```

3. Настройка переменных окружения:
```bash
cp .env.example .env
# Отредактируйте .env, добавив ваши API ключи
```

4. Загрузка датасета:
```bash
mkdir -p data
# Загрузите ru_rag_test_dataset.pkl из https://github.com/slivka83/ru_rag_test_dataset
# Поместите файл в директорию data/
```

### Запуск первого эксперимента

```bash
# Проверка окружения
poetry run rag check-env

# Запуск базового эксперимента
poetry run rag run configs/experiments/baseline_vector.yaml

# Просмотр результатов
poetry run rag view-results results/experiments/baseline_vector_*.json
```

## Архитектура системы

Платформа построена на принципах модульности и расширяемости. Каждый компонент RAG-конвейера реализован как независимый модуль с единым интерфейсом.

### Основные принципы:

1. **Модульность**: Каждый этап конвейера представлен отдельным компонентом
2. **Регистрация компонентов**: Централизованный реестр для управления компонентами
3. **Конфигурация через YAML**: Декларативное описание экспериментов
4. **Автоматическая оценка**: Интеграция с RAGAS для метрик качества

## Компоненты платформы

### Загрузчики данных (rag_platform/loaders/)

#### PickleLoader
Загрузка предварительно обработанных данных из pickle файлов. Поддерживает датасеты с вопросами, ответами и контекстами.

#### WikipediaLoader  
Загрузка статей из Wikipedia API. Позволяет загружать полные статьи по заданным запросам.

#### FileLoader
Универсальный загрузчик для текстовых файлов различных форматов.

#### HybridLoader
Комбинирует несколько источников данных, объединяя Wikipedia статьи с QA датасетами.

### Стратегии разбиения текста (rag_platform/chunkers/)

#### RecursiveChunker
Рекурсивное разбиение текста с учетом структуры документа. Сохраняет семантическую целостность фрагментов.

#### FixedChunker
Разбиение на фрагменты фиксированного размера. Простой и предсказуемый метод.

#### SentenceChunker
Разбиение по границам предложений. Гарантирует целостность предложений в фрагментах.

### Модели эмбеддингов (rag_platform/embeddings/)

#### OpenAIEmbedding
Интеграция с OpenAI embedding API. Поддерживает модели:
- text-embedding-3-small (1536 размерность)
- text-embedding-3-large (3072 размерность)

### Векторные хранилища (rag_platform/vectorstores/)

#### ChromaVectorStore
Локальное векторное хранилище на базе ChromaDB. Поддерживает персистентность и различные метрики расстояния.

### Стратегии поиска (rag_platform/retrievers/)

#### VectorRetriever
Базовый векторный поиск по косинусному сходству. Поддерживает similarity и MMR поиск.

#### HybridRetriever
Гибридный поиск, комбинирующий векторный и ключевой поиск. Использует RRF (Reciprocal Rank Fusion) для объединения результатов.

#### RerankerRetriever
Двухэтапный поиск с переранжированием. Использует cross-encoder модели для улучшения релевантности.

#### GraphRetriever
Поиск на основе графа знаний. Поддерживает локальный и глобальный поиск по сообществам в графе.

### RAG цепочки (rag_platform/chains/)

#### VanillaRAGChain
Базовая реализация RAG. Простая цепочка: поиск → формирование контекста → генерация ответа.

#### GraphRAGChain
Продвинутая реализация с использованием графа знаний. Включает:
- Извлечение сущностей и связей
- Построение графа знаний
- Поиск по графу с учетом топологии

### Система оценки (rag_platform/evaluation/)

#### RAGASEvaluator
Интеграция с библиотекой RAGAS для оценки качества RAG систем. Метрики:
- **Faithfulness**: Соответствие ответа предоставленному контексту
- **Answer Relevancy**: Релевантность ответа вопросу
- **Context Precision**: Точность извлеченного контекста
- **Context Recall**: Полнота извлеченного контекста

## Конфигурации экспериментов

### baseline_vector.yaml
**Описание**: Базовая конфигурация для установления минимального порога качества.

**Характеристики**:
- Модель: gpt-4.1-nano
- Эмбеддинги: text-embedding-3-small
- Поиск: векторный (top-5)
- Разбиение: рекурсивное (1000 символов)

**Применение**: Начальная точка для сравнения, оценка базовой производительности.

### enhanced_hybrid.yaml
**Описание**: Улучшенная конфигурация с гибридным поиском.

**Характеристики**:
- Модель: gpt-4.1-nano
- Эмбеддинги: text-embedding-3-small
- Поиск: гибридный (векторный + ключевой)
- Разбиение: по предложениям

**Применение**: Повышение качества поиска за счет комбинирования методов.

### advanced_reranker.yaml
**Описание**: Продвинутая конфигурация с переранжированием результатов.

**Характеристики**:
- Модель: gpt-4.1-nano
- Эмбеддинги: text-embedding-3-large
- Поиск: векторный с переранжированием
- Разбиение: рекурсивное (800 символов)

**Применение**: Максимизация релевантности через двухэтапный поиск.

### pro_graphrag.yaml
**Описание**: Экспериментальная конфигурация с графом знаний.

**Характеристики**:
- Модель: gpt-4.1-nano
- Эмбеддинги: text-embedding-3-small
- Поиск: графовый (локальный + глобальный)
- Граф: извлечение сущностей, детекция сообществ

**Применение**: Исследование возможностей GraphRAG для сложных запросов.

## Структура проекта

```
rag/
├── rag_platform/          # Основные модули платформы
│   ├── core/             # Базовые классы и регистрация
│   ├── loaders/          # Загрузчики данных
│   ├── chunkers/         # Стратегии разбиения
│   ├── embeddings/       # Модели эмбеддингов
│   ├── vectorstores/     # Векторные хранилища
│   ├── retrievers/       # Стратегии поиска
│   ├── chains/           # RAG цепочки
│   ├── graph/            # Компоненты GraphRAG
│   ├── evaluation/       # Система оценки
│   └── cli.py           # Интерфейс командной строки
├── configs/              # Конфигурации
│   └── experiments/      # Конфигурации экспериментов
├── data/                # Датасеты
├── results/             # Результаты экспериментов
│   └── experiments/     # JSON файлы с результатами
├── tests/               # Тесты
│   ├── unit/           # Модульные тесты
│   └── integration/    # Интеграционные тесты
└── scripts/            # Вспомогательные скрипты
```

## Команды CLI

```bash
# Основные команды
rag run <config>          # Запуск эксперимента
rag list-components       # Список доступных компонентов
rag create-config <path>  # Создание примера конфигурации
rag view-results <path>   # Просмотр результатов
rag check-env            # Проверка настройки окружения
rag compare              # Сравнение результатов экспериментов
```

## Разработка и расширение

### Создание конфигурации эксперимента

```yaml
name: my_experiment
description: Описание эксперимента

data:
  source: local
  path: ./data/dataset.pkl
  loader: pickle_loader

chunking:
  strategy: recursive
  chunk_size: 1000
  chunk_overlap: 200

llm:
  provider: openai
  model: gpt-4.1-nano
  temperature: 0.1
```

## Тестирование

```bash
# Запуск всех тестов
poetry run pytest

# Запуск модульных тестов
poetry run pytest tests/unit/

# Запуск интеграционных тестов
poetry run pytest tests/integration/

# Тестирование с покрытием
poetry run pytest --cov=rag_platform
```

## Требования и зависимости

### Основные зависимости:
- langchain и langchain-community
- openai
- chromadb
- ragas
- pandas
- networkx (для GraphRAG)
- scikit-learn (для метрик)
- sentence-transformers (для переранжирования)

### Системные требования:
- RAM: минимум 8GB (рекомендуется 16GB)
- Дисковое пространство: 5GB для векторных индексов
- GPU: опционально для локальных моделей

## Оценка стоимости

### OpenAI API (на 1000 документов):
- text-embedding-3-small: ~$0.10
- text-embedding-3-large: ~$0.65

### LLM (на 100 запросов):
- gpt-4.1-nano: ~$0.05
- gpt-4o-mini (для RAGAS): ~$0.10

## Результаты экспериментов

### Сравнение конфигураций RAG

Проведено сравнение трех конфигураций RAG на полном датасете (1,708 документов, 100 вопросов):

#### 🏆 Итоговый рейтинг

| Место | Конфигурация | Средний RAGAS | Faithfulness | Answer Relevancy | Context Precision | Context Recall |
|-------|--------------|---------------|--------------|------------------|-------------------|----------------|
| **1** | **Advanced Reranker** | **0.8352** | 0.7953 | 0.6826 | 0.9227 | 0.9400 |
| 2 | Baseline | 0.7448 | 0.7125 | 0.6261 | 0.7895 | 0.8500 |
| 3 | Enhanced Hybrid | 0.7387 | 0.7817 | 0.6114 | 0.7542 | 0.8075 |

#### 📊 Детальное сравнение

| Параметр | Baseline | Enhanced Hybrid | Advanced Reranker |
|----------|----------|-----------------|-------------------|
| **Модель LLM** | gpt-4.1-nano | gpt-4.1-nano | gpt-4.1-nano |
| **Модель эмбеддингов** | text-embedding-3-small | text-embedding-3-small | text-embedding-3-large |
| **Размер чанка** | 512 | 350 | 800 |
| **Стратегия разбиения** | recursive | sentence | recursive |
| **Количество контекстов (k)** | 5 | 5 | 5 |
| **Среднее время обработки** | 1.26 сек | 1.17 сек | 1.20 сек |
| **Стоимость за запрос** | $0.005 | $0.005 | $0.005 |

#### 🎯 Ключевые выводы

1. **Advanced Reranker показал лучшие результаты**:
   - Превосходная точность контекста (92.3%) и полнота (94.0%)
   - Использование больших эмбеддингов (3072 размерность) значительно улучшает качество
   - Увеличенный размер чанков (800 токенов) помогает сохранить больше контекста

2. **Baseline обеспечивает хороший баланс**:
   - Стабильные метрики по всем категориям
   - Оптимальное соотношение качества и простоты
   - Рекомендуется для начальной реализации

3. **Enhanced Hybrid показал смешанные результаты**:
   - Sentence-based разбиение не дало ожидаемого улучшения
   - Меньший размер чанков (350) ограничил контекстную информацию

#### 📈 Метрики производительности

- **Индексировано документов**: 1,708 (785 Wikipedia + 923 QA пар)
- **Создано чанков**: 2,615-3,709 (в зависимости от стратегии)
- **Оценено вопросов**: 100 на эксперимент
- **Использован улучшенный RAGAS**: С поддержкой русского языка
